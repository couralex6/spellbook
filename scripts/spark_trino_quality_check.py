import json
from pprint import pprint

import requests

from trino import dbapi
from trino.auth import BasicAuthentication
from trino.exceptions import TrinoUserError
import os


def get_tables_from_manifest(manifest_path):
    '''
    returns a csv of tables from a manifest file. We filter out
    '''
    table_csv_str = "schema, table, materialized, created_at, partition_by\n"
    with open(manifest_path, "r") as f:
        manifest = json.load(f)
    for node_name in manifest["nodes"]:
        node_data = manifest["nodes"][node_name]
        if node_data["resource_type"] == "model":
            schema = node_data["schema"]
            table = node_data["alias"]
            materialized = node_data["config"]["materialized"]
            created_at = node_data["created_at"]
            partition_by = None
            if "partition_by" in node_data["config"]:
                partition_by = node_data["config"]["partition_by"][0]
            row = f"{schema}, {table}, {materialized}, {created_at}, {partition_by}\n"
            table_csv_str += row

    return table_csv_str


def upload_csv(table_csv, target):
    '''
    Upload CSV string to dune.

    target = "trino" | "spark"
    '''
    # if target not in ("trino", "spark"):
    #     raise ValueError("target must be 'trino' or 'spark'")

    url = 'https://api.dev.dune.com/api/v1/table/upload/csv'
    api_key = os.environ.get('DUNE_API_KEY')
    headers = {'X-Dune-Api-Key': api_key}
    table_name = target
    payload = {
        "table_name": table_name,
        "description": "Tables generated by Spark Spellbook.",
        "data": table_csv
    }
    response = requests.post(url, data=json.dumps(payload), headers=headers)
    if response.status_code == 200 and response.json()['success']:
        print(f'Success writing CSV to delta_dev.dune_upload.{table_name} ', flush=True)
    else:
        print('Error writing CSV to Dune.com!')
        raise Exception(response.content)

# def databricks_client():
#     '''
#     NOT NEEDED ANYMORE
#     Return client for databricks SQL warehouse to query tables generated by Spark Spellbook.
#     '''
#     connection = sql.connect(
#         server_hostname=os.environ["DATABRICKS_HOST"],
#         http_path=os.environ["DATABRICKS_HTTP_PATH"],
#         access_token=os.environ["DATABRICKS_ACCESS_TOKEN"])
#
#     return connection

#
def trino_client():
    """
    Function that executes a query passed as a string against the trino server. We would like to use aws secrets
    manager to authenticate.
    """
    username = os.environ.get('TRINO_USERNAME')
    password = os.environ.get('TRINO_PASSWORD')

    # Creating a connection to the trino server
    trino_host = os.environ.get('TRINO_URL')
    conn = dbapi.connect(
        host=trino_host,
        port=443,
        auth=BasicAuthentication(username, password),
        http_scheme="https",
        client_tags=["routingGroup=sandbox"],
    )

    return conn
#
#
def execute_query(connection, query):
    '''
    Execute query and return results.
    '''
    cursor = connection.cursor()
    cursor.execute(query)
    response = cursor.fetchall()
    cursor.close()
    return response

def generate_information_schema(rows):
    '''
    Generate information schema from rows returned from query.
    '''
    information_schema_csv = "table_catalog, table_schema, table_name, table_type\n"
    for row in rows:
        information_schema_csv += f'{row[0]},{row[1]},{row[2]},{row[3]}\n'
    upload_csv(information_schema_csv, "trino_spells_information_schema")



if __name__ == "__main__":

    # get all tables and schemas from hive.INFORMATION_SCHEMA.tables (trino only)
    trino_conn = trino_client()
    query = "select * from  hive.INFORMATION_SCHEMA.tables where table_schema like 'dbt_%'"
    result = execute_query(trino_conn, query)
    generate_information_schema(result)
    trino_conn.close()


    #get all models compile into manifest (trino and spark)
    spark_tables = get_tables_from_manifest("spark_manifest.json")
    upload_csv(spark_tables, "spark_spellbook_status")

    trino_tables = get_tables_from_manifest("trino_manifest.json")
    upload_csv(trino_tables, "trino_spellbook_status")